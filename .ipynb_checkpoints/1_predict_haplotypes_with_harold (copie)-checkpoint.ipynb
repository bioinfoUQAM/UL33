{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = \"data\"\n",
    "JAR_LIBS = \"lib/htsjdk-unspecified-SNAPSHOT.jar:lib/picocli-4.1.2.jar:lib/pal-1.5.1.jar:lib/cache2k-all-1.0.2.Final.jar:lib/commons-math3-3.6.1.jar\"\n",
    "JAR_DIR = \"jar\"\n",
    "FASTA_REF = os.path.join(DATA_DIR, \"fasta/HCMV_Merlin_UL33.fasta\")\n",
    "SAMPLES = [\"04.B1.W14.01\", \"04.M1.W09.02\", \"05.B1.W14.04\", \"05.M1.W08.03\", \"27.B1.W13.06\", \"27.M1.W10.07\", \"30.B1.W11.08\",\n",
    "           \"30.M1.W04.09\", \"38.B1.W10.11\", \"38.M1.W03.10\", \"39.B1.W11.12\", \"39.M1.W03.13\", \"39.M1.W05.14\", \"53.B1.W14.17\", \n",
    "           \"53.M1.W07.16\", \"56.B1.W09.22\", \"56.M1.W03.21\", \"63.B1.W09.29\", \"63.M1.W02.30\", \"66.B1.W09.25\", \"66.M1.W02.24\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to  move the file from src to dest\n",
    "def move_file(src, dest):\n",
    "    try: shutil.move(src, dest)\n",
    "    except FileNotFoundError as e: print(f\"Error moving or copying file from {src} to {dest}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate strandcount for the given sample\n",
    "def generate_strandcount(sample):\n",
    "    sample_dir = os.path.join(DATA_DIR, sample)\n",
    "    command = f\"java -cp {JAR_LIBS}:{JAR_DIR}/MakeReadCount.jar makereadcount.MakeReadCount {sample_dir}/{sample}.bam\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)\n",
    "    move_file(f\"{sample}.log\", f\"{sample_dir}/{sample}.log\")\n",
    "    move_file(f\"{sample}.strandcount.csv\", f\"{sample_dir}/{sample}.strandcount.csv\")\n",
    "    with open(os.path.join(sample_dir, \"sample.txt\"), 'w') as file: file.write(f\"{sample}.strandcount.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run HaROLD for the given sample and haplotypes\n",
    "def run_harold(sample, haplotypes):\n",
    "    command = f\"java -Xmx16384m -jar {JAR_DIR}/Cluster_RG/dist/HaROLD-2.0.jar --count-file {DATA_DIR}/{sample}/sample.txt --haplotypes {haplotypes} --alpha-frac 0.5 --gamma-cache 10000 -H -L --threads 12 -p {DATA_DIR}/{sample}/{sample} --seed 1\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to refine HaROLD output for the given sample and output directory\n",
    "def refine_harold_output(sample, output_directory):\n",
    "    command = f\"java -Xmx16384m -cp {JAR_LIBS}:{JAR_DIR}/RefineHaplotypes.jar refineHaplotypes.RefineHaplotypes -t {DATA_DIR}/{sample}/{sample} --bam {DATA_DIR}/{sample}/{sample}.bam --baseFreq {output_directory}/step_1/{sample}.lld --refSequence {FASTA_REF} --hapAlignment {output_directory}/step_1/{sample}Haplo.fasta --iterate\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the entire pipeline for a given sample\n",
    "def run_pipeline(sample):\n",
    "    # Generate strandcount for the sample\n",
    "    generate_strandcount(sample)\n",
    "\n",
    "    # Iterate over haplotype values from 2 to 5\n",
    "    for n in range(1, 11):\n",
    "        output_directory = os.path.join(DATA_DIR, sample, f\"{n}\")\n",
    "        sub_dirs = [output_directory, os.path.join(output_directory, \"step_1\"), os.path.join(output_directory, \"step_2\")]\n",
    "\n",
    "        # Create necessary subdirectories\n",
    "        for sub_dir in sub_dirs:\n",
    "            if not os.path.exists(sub_dir):\n",
    "                os.makedirs(sub_dir)\n",
    "                \n",
    "        # Run HaROLD for the sample with current haplotype value and move necessary files\n",
    "        run_harold(sample, 5)\n",
    "        files_to_move = [\".lld\", \".log\", \"Haplo.fasta\"]\n",
    "        for ext in files_to_move:\n",
    "            move_file(os.path.join(DATA_DIR, sample, f\"{sample}{ext}\"), os.path.join(output_directory, \"step_1\", f\"{sample}{ext}\"))\n",
    "\n",
    "        # Refine HaROLD output and move the refined output files\n",
    "        refine_harold_output(sample, output_directory)\n",
    "        move_file(os.path.join(DATA_DIR, sample, f\"{sample}.log\"), os.path.join(output_directory, \"step_2\", f\"{sample}.log\"))\n",
    "        move_file(os.path.join(DATA_DIR, sample, f\"{sample}.fasta\"), os.path.join(output_directory, \"step_2\", f\"{sample}.fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample: 04.B1.W14.01\n",
      "Processing sample: 04.M1.W09.02\n",
      "Processing sample: 05.B1.W14.04\n",
      "Processing sample: 05.M1.W08.03\n",
      "Processing sample: 27.B1.W13.06\n",
      "Processing sample: 27.M1.W10.07\n",
      "Processing sample: 30.B1.W11.08\n",
      "Processing sample: 30.M1.W04.09\n",
      "Processing sample: 38.B1.W10.11\n",
      "Processing sample: 38.M1.W03.10\n",
      "Processing sample: 39.B1.W11.12\n",
      "Processing sample: 39.M1.W03.13\n",
      "Processing sample: 39.M1.W05.14\n",
      "Processing sample: 53.B1.W14.17\n",
      "Processing sample: 53.M1.W07.16\n",
      "Processing sample: 56.B1.W09.22\n",
      "Processing sample: 56.M1.W03.21\n",
      "Processing sample: 63.B1.W09.29\n",
      "Processing sample: 63.M1.W02.30\n",
      "Processing sample: 66.B1.W09.25\n"
     ]
    }
   ],
   "source": [
    "# Loop over all samples to run the pipeline\n",
    "for sample in SAMPLES:\n",
    "    print(f\"Processing sample: {sample}\")\n",
    "    run_pipeline(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1d675c2f4f889dd09212fec10ba36e21d8557edcac2b728432b54c97897b7bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
